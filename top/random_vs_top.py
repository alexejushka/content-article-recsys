import numpy as np
import pandas as pd
from typing import Dict, List, Tuple
import random
import pickle

def age_group(age):
    """–ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –≤–æ–∑—Ä–∞—Å—Ç–∞ –≤ –≥—Ä—É–ø–ø—É"""
    if age < 18:
        return 0  # '0-17'
    elif age < 30:
        return 1  # '18-29'
    elif age < 45:
        return 2  # '30-44'
    elif age < 60:
        return 3  # '45-59'
    else:
        return 4  # '60+'


def prepare_recommendation_systems(clicked_df: pd.DataFrame, n_top: int = 10) -> Dict:
    """
    –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –≤—Å–µ—Ö —Ç—Ä–µ—Ö —Å–∏—Å—Ç–µ–º —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π:
    1. –°–µ–≥–º–µ–Ω—Ç–Ω—ã–µ —Ç–æ–ø—ã (–ø–æ –ø–æ–ª—É –∏ –≤–æ–∑—Ä–∞—Å—Ç—É)
    2. –û–±—â–∏–π —Ç–æ–ø –¥–ª—è –≤—Å–µ—Ö
    3. –†–∞–Ω–¥–æ–º (–¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è)
    
    Returns:
        Dict —Å —Ç–æ–ø–∞–º–∏ –¥–ª—è –∫–∞–∂–¥–æ–π —Å–∏—Å—Ç–µ–º—ã
    """
    
    # 1. –°–ï–ì–ú–ï–ù–¢–ù–´–ï –¢–û–ü–´ (–ø–æ –ø–æ–ª—É –∏ –≤–æ–∑—Ä–∞—Å—Ç—É)
    grouped = (
        clicked_df.groupby(['gender', 'age_group', 'article_id'])
        .size()
        .reset_index(name='clicks')
    )
    
    top_articles_by_segment = (
        grouped
        .sort_values(['gender', 'age_group', 'clicks'], ascending=[True, True, False])
        .groupby(['gender', 'age_group'])['article_id']
        .apply(lambda x: x.head(n_top).tolist())
        .to_dict()
    )
    
    # 2. –û–ë–©–ò–ô –¢–û–ü (–±–µ–∑ —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏)
    global_top = (
        clicked_df.groupby('article_id')
        .size()
        .reset_index(name='clicks')
        .sort_values('clicks', ascending=False)
        .head(n_top)['article_id']
        .tolist()
    )
    
    # 3. –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Å—Ç–∞—Ç—å—è—Ö
    articles_info = clicked_df[['article_id', 'title', 'url']].drop_duplicates()
    
    return {
        'segment_tops': top_articles_by_segment,
        'global_top': global_top,
        'articles_info': articles_info,
        'all_articles': list(clicked_df['article_id'].unique())
    }


def evaluate_all_methods(clicked_df: pd.DataFrame, 
                        recommendation_systems: Dict,
                        n_recommendations: int = 10,
                        n_random_iterations: int = 100) -> Dict:
    """
    –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –≤—Å–µ—Ö —Ç—Ä–µ—Ö –º–µ—Ç–æ–¥–æ–≤:
    1. –°–µ–≥–º–µ–Ω—Ç–Ω—ã–µ —Ç–æ–ø—ã
    2. –û–±—â–∏–π —Ç–æ–ø
    3. –†–∞–Ω–¥–æ–º
    """
    
    segment_tops = recommendation_systems['segment_tops']
    global_top = recommendation_systems['global_top'][:n_recommendations]
    all_articles = recommendation_systems['all_articles']
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–µ—Ç—Ä–∏–∫
    metrics = {
        'segment': {'hits': 0, 'total_clicks': [], 'precisions': []},
        'global': {'hits': 0, 'total_clicks': [], 'precisions': []},
        'random': {'hits': [], 'total_clicks': [], 'precisions': []}
    }
    
    # –£–Ω–∏–∫–∞–ª—å–Ω—ã–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–∏
    users = clicked_df[['ehr_id', 'gender', 'age_group']].drop_duplicates()
    total_users = len(users)
    
    print(f"–û—Ü–µ–Ω–∏–≤–∞–µ–º {total_users} –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π –ø–æ —Ç—Ä–µ–º –º–µ—Ç–æ–¥–∞–º...")
    
    for _, user_row in users.iterrows():
        user_id = user_row['ehr_id']
        gender = user_row['gender']
        age_grp = user_row['age_group']
        
        # –°—Ç–∞—Ç—å–∏, –∫–æ—Ç–æ—Ä—ã–µ –∫–ª–∏–∫–Ω—É–ª –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å
        user_clicks = set(clicked_df[clicked_df['ehr_id'] == user_id]['article_id'].unique())
        n_user_clicks = len(user_clicks)
        
        # 1. –°–ï–ì–ú–ï–ù–¢–ù–´–ï –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò
        segment_recs = segment_tops.get((gender, age_grp), [])[:n_recommendations]
        segment_recs_set = set(segment_recs)
        segment_matches = user_clicks & segment_recs_set
        
        if segment_matches:
            metrics['segment']['hits'] += 1
        metrics['segment']['total_clicks'].append(len(segment_matches))
        if len(segment_recs) > 0:
            metrics['segment']['precisions'].append(len(segment_matches) / len(segment_recs))
        
        # 2. –û–ë–©–ò–ô –¢–û–ü
        global_recs_set = set(global_top)
        global_matches = user_clicks & global_recs_set
        
        if global_matches:
            metrics['global']['hits'] += 1
        metrics['global']['total_clicks'].append(len(global_matches))
        if len(global_top) > 0:
            metrics['global']['precisions'].append(len(global_matches) / len(global_top))
        
        # 3. –†–ê–ù–î–û–ú–ù–´–ï –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò (—É—Å—Ä–µ–¥–Ω—è–µ–º –ø–æ –∏—Ç–µ—Ä–∞—Ü–∏—è–º)
        user_random_hits = []
        user_random_clicks = []
        user_random_precisions = []
        
        for _ in range(n_random_iterations):
            random_recs = random.sample(all_articles, min(n_recommendations, len(all_articles)))
            random_recs_set = set(random_recs)
            random_matches = user_clicks & random_recs_set
            
            user_random_hits.append(1 if random_matches else 0)
            user_random_clicks.append(len(random_matches))
            user_random_precisions.append(len(random_matches) / len(random_recs))
        
        metrics['random']['hits'].append(np.mean(user_random_hits))
        metrics['random']['total_clicks'].append(np.mean(user_random_clicks))
        metrics['random']['precisions'].append(np.mean(user_random_precisions))
    
    # –†–∞—Å—á–µ—Ç —Ñ–∏–Ω–∞–ª—å–Ω—ã—Ö –º–µ—Ç—Ä–∏–∫
    results = {}
    
    # –°–µ–≥–º–µ–Ω—Ç–Ω—ã–µ —Ç–æ–ø—ã
    results['segment'] = {
        'hit_rate': metrics['segment']['hits'] / total_users,
        'avg_clicks_in_top': np.mean(metrics['segment']['total_clicks']),
        'median_clicks_in_top': np.median(metrics['segment']['total_clicks']),
        'precision': np.mean(metrics['segment']['precisions']),
        'users_with_hits': metrics['segment']['hits']
    }
    
    # –û–±—â–∏–π —Ç–æ–ø
    results['global'] = {
        'hit_rate': metrics['global']['hits'] / total_users,
        'avg_clicks_in_top': np.mean(metrics['global']['total_clicks']),
        'median_clicks_in_top': np.median(metrics['global']['total_clicks']),
        'precision': np.mean(metrics['global']['precisions']),
        'users_with_hits': metrics['global']['hits']
    }
    
    # –†–∞–Ω–¥–æ–º
    results['random'] = {
        'hit_rate': np.mean(metrics['random']['hits']),
        'avg_clicks_in_top': np.mean(metrics['random']['total_clicks']),
        'median_clicks_in_top': np.median(metrics['random']['total_clicks']),
        'precision': np.mean(metrics['random']['precisions']),
        'users_with_hits': int(np.sum(metrics['random']['hits']))
    }
    
    # –£–ª—É—á—à–µ–Ω–∏—è –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ —Ä–∞–Ω–¥–æ–º–∞
    for method in ['segment', 'global']:
        results[f'{method}_vs_random'] = {
            'hit_rate_improvement': (results[method]['hit_rate'] / results['random']['hit_rate'] - 1) * 100,
            'avg_clicks_improvement': (results[method]['avg_clicks_in_top'] / results['random']['avg_clicks_in_top'] - 1) * 100,
            'precision_improvement': (results[method]['precision'] / results['random']['precision'] - 1) * 100
        }
    
    # –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å–µ–≥–º–µ–Ω—Ç–Ω–æ–≥–æ –∏ –≥–ª–æ–±–∞–ª—å–Ω–æ–≥–æ
    results['segment_vs_global'] = {
        'hit_rate_improvement': (results['segment']['hit_rate'] / results['global']['hit_rate'] - 1) * 100,
        'avg_clicks_improvement': (results['segment']['avg_clicks_in_top'] / results['global']['avg_clicks_in_top'] - 1) * 100,
        'precision_improvement': (results['segment']['precision'] / results['global']['precision'] - 1) * 100
    }
    
    return results


def calculate_precision_at_k_all_methods(clicked_df: pd.DataFrame,
                                         recommendation_systems: Dict,
                                         k_values: List[int] = [1, 3, 5, 10]) -> pd.DataFrame:
    """
    –†–∞—Å—á–µ—Ç Precision@K –¥–ª—è –≤—Å–µ—Ö —Ç—Ä–µ—Ö –º–µ—Ç–æ–¥–æ–≤
    """
    segment_tops = recommendation_systems['segment_tops']
    global_top = recommendation_systems['global_top']
    all_articles = recommendation_systems['all_articles']
    
    results = []
    users = clicked_df[['ehr_id', 'gender', 'age_group']].drop_duplicates()
    
    for k in k_values:
        segment_precisions = []
        global_precisions = []
        random_precisions = []
        
        for _, user_row in users.iterrows():
            user_id = user_row['ehr_id']
            gender = user_row['gender']
            age_grp = user_row['age_group']
            
            user_clicks = set(clicked_df[clicked_df['ehr_id'] == user_id]['article_id'].unique())
            
            # –°–µ–≥–º–µ–Ω—Ç–Ω—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
            segment_recs = segment_tops.get((gender, age_grp), [])[:k]
            if segment_recs:
                segment_precision = len(set(segment_recs) & user_clicks) / k
                segment_precisions.append(segment_precision)
            
            # –ì–ª–æ–±–∞–ª—å–Ω—ã–π —Ç–æ–ø
            global_recs = global_top[:k]
            if global_recs:
                global_precision = len(set(global_recs) & user_clicks) / k
                global_precisions.append(global_precision)
            
            # –†–∞–Ω–¥–æ–º–Ω—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ (—É—Å—Ä–µ–¥–Ω—è–µ–º)
            random_precision_iter = []
            for _ in range(100):
                random_recs = random.sample(all_articles, min(k, len(all_articles)))
                random_precision = len(set(random_recs) & user_clicks) / k
                random_precision_iter.append(random_precision)
            random_precisions.append(np.mean(random_precision_iter))
        
        results.append({
            'K': k,
            'Precision@K_segment': np.mean(segment_precisions),
            'Precision@K_global': np.mean(global_precisions),
            'Precision@K_random': np.mean(random_precisions),
            'Segment_vs_Random_%': ((np.mean(segment_precisions) / np.mean(random_precisions)) - 1) * 100,
            'Global_vs_Random_%': ((np.mean(global_precisions) / np.mean(random_precisions)) - 1) * 100,
            'Segment_vs_Global_%': ((np.mean(segment_precisions) / np.mean(global_precisions)) - 1) * 100
        })
    
    return pd.DataFrame(results)


def analyze_coverage_all_methods(clicked_df: pd.DataFrame,
                                 recommendation_systems: Dict,
                                 n_recommendations: int = 10) -> Dict:
    """
    –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –ø–æ–∫—Ä—ã—Ç–∏—è –∫–∞—Ç–∞–ª–æ–≥–∞ –¥–ª—è –≤—Å–µ—Ö –º–µ—Ç–æ–¥–æ–≤
    """
    segment_tops = recommendation_systems['segment_tops']
    global_top = recommendation_systems['global_top'][:n_recommendations]
    all_articles = set(recommendation_systems['all_articles'])
    n_articles = len(all_articles)
    
    # 1. –ü–æ–∫—Ä—ã—Ç–∏–µ —Å–µ–≥–º–µ–Ω—Ç–Ω—ã–º–∏ —Ç–æ–ø–∞–º–∏
    segment_articles = set()
    for articles_list in segment_tops.values():
        segment_articles.update(articles_list[:n_recommendations])
    segment_coverage = len(segment_articles) / n_articles
    
    # 2. –ü–æ–∫—Ä—ã—Ç–∏–µ –≥–ª–æ–±–∞–ª—å–Ω—ã–º —Ç–æ–ø–æ–º
    global_coverage = len(set(global_top)) / n_articles
    
    # 3. –ü–æ–∫—Ä—ã—Ç–∏–µ —Ä–∞–Ω–¥–æ–º–æ–º (—Å–∏–º—É–ª—è—Ü–∏—è)
    n_segments = len(segment_tops)  # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–µ–≥–º–µ–Ω—Ç–æ–≤
    simulated_coverage = []
    
    for _ in range(100):
        random_articles = set()
        # –°–∏–º—É–ª–∏—Ä—É–µ–º —Ä–∞–Ω–¥–æ–º–Ω—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Å–µ–≥–º–µ–Ω—Ç–∞
        for _ in range(n_segments):
            random_sample = random.sample(list(all_articles), 
                                        min(n_recommendations, n_articles))
            random_articles.update(random_sample)
        simulated_coverage.append(len(random_articles) / n_articles)
    
    # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏—è
    # Gini –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –Ω–µ—Ä–∞–≤–Ω–æ–º–µ—Ä–Ω–æ—Å—Ç–∏ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è
    def calculate_gini(article_counts):
        sorted_counts = sorted(article_counts)
        n = len(sorted_counts)
        cumsum = np.cumsum(sorted_counts)
        return (2 * np.sum((np.arange(1, n+1) * sorted_counts))) / (n * np.sum(sorted_counts)) - (n + 1) / n
    
    # –ü–æ–¥—Å—á–µ—Ç —á–∞—Å—Ç–æ—Ç –¥–ª—è —Å–µ–≥–º–µ–Ω—Ç–Ω—ã—Ö —Ç–æ–ø–æ–≤
    segment_freq = {}
    for articles_list in segment_tops.values():
        for article in articles_list[:n_recommendations]:
            segment_freq[article] = segment_freq.get(article, 0) + 1
    
    segment_gini = calculate_gini(list(segment_freq.values())) if segment_freq else 0
    
    return {
        'segment_coverage': segment_coverage,
        'global_coverage': global_coverage,
        'random_coverage': np.mean(simulated_coverage),
        'segment_unique_articles': len(segment_articles),
        'global_unique_articles': len(set(global_top)),
        'segment_gini': segment_gini,
        'concentration_ratio_segment_vs_random': segment_coverage / np.mean(simulated_coverage),
        'concentration_ratio_global_vs_random': global_coverage / np.mean(simulated_coverage)
    }


def statistical_significance_test(clicked_df: pd.DataFrame,
                                 recommendation_systems: Dict,
                                 n_recommendations: int = 10,
                                 n_bootstrap: int = 1000) -> Dict:
    """
    Bootstrap —Ç–µ—Å—Ç –¥–ª—è —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–æ–π –∑–Ω–∞—á–∏–º–æ—Å—Ç–∏ —Ä–∞–∑–ª–∏—á–∏–π –º–µ–∂–¥—É –º–µ—Ç–æ–¥–∞–º–∏
    """
    segment_tops = recommendation_systems['segment_tops']
    global_top = recommendation_systems['global_top'][:n_recommendations]
    all_articles = recommendation_systems['all_articles']
    
    users = clicked_df[['ehr_id', 'gender', 'age_group']].drop_duplicates()
    
    segment_hit_rates = []
    global_hit_rates = []
    random_hit_rates = []
    
    for _ in range(n_bootstrap):
        # –°—ç–º–ø–ª–∏—Ä—É–µ–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π —Å –≤–æ–∑–≤—Ä–∞—Ç–æ–º
        sampled_users = users.sample(n=len(users), replace=True)
        
        segment_hits = 0
        global_hits = 0
        random_hits = 0
        
        for _, user_row in sampled_users.iterrows():
            user_clicks = set(clicked_df[clicked_df['ehr_id'] == user_row['ehr_id']]['article_id'])
            
            # –°–µ–≥–º–µ–Ω—Ç–Ω—ã–µ
            segment_recs = set(segment_tops.get(
                (user_row['gender'], user_row['age_group']), [])[:n_recommendations])
            if user_clicks & segment_recs:
                segment_hits += 1
            
            # –ì–ª–æ–±–∞–ª—å–Ω—ã–µ
            global_recs = set(global_top)
            if user_clicks & global_recs:
                global_hits += 1
            
            # –†–∞–Ω–¥–æ–º–Ω—ã–µ
            random_recs = set(random.sample(all_articles, min(n_recommendations, len(all_articles))))
            if user_clicks & random_recs:
                random_hits += 1
        
        segment_hit_rates.append(segment_hits / len(sampled_users))
        global_hit_rates.append(global_hits / len(sampled_users))
        random_hit_rates.append(random_hits / len(sampled_users))
    
    # –°—á–∏—Ç–∞–µ–º —Ä–∞–∑–ª–∏—á–∏—è –∏ p-values
    segment_vs_random = np.array(segment_hit_rates) - np.array(random_hit_rates)
    global_vs_random = np.array(global_hit_rates) - np.array(random_hit_rates)
    segment_vs_global = np.array(segment_hit_rates) - np.array(global_hit_rates)
    
    return {
        'segment_vs_random': {
            'mean_diff': np.mean(segment_vs_random),
            'ci_95': [np.percentile(segment_vs_random, 2.5), np.percentile(segment_vs_random, 97.5)],
            'p_value': np.mean(segment_vs_random <= 0),
            'significant': np.mean(segment_vs_random <= 0) < 0.05
        },
        'global_vs_random': {
            'mean_diff': np.mean(global_vs_random),
            'ci_95': [np.percentile(global_vs_random, 2.5), np.percentile(global_vs_random, 97.5)],
            'p_value': np.mean(global_vs_random <= 0),
            'significant': np.mean(global_vs_random <= 0) < 0.05
        },
        'segment_vs_global': {
            'mean_diff': np.mean(segment_vs_global),
            'ci_95': [np.percentile(segment_vs_global, 2.5), np.percentile(segment_vs_global, 97.5)],
            'p_value': np.mean(segment_vs_global <= 0),
            'significant': np.mean(segment_vs_global <= 0) < 0.05
        }
    }


def print_full_comparison_report(clicked_df: pd.DataFrame,
                                n_recommendations: int = 10):
    """
    –ü–æ–ª–Ω—ã–π –æ—Ç—á–µ—Ç —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –≤—Å–µ—Ö —Ç—Ä–µ—Ö –º–µ—Ç–æ–¥–æ–≤
    """
    # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —Å–∏—Å—Ç–µ–º —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π
    print("–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —Å–∏—Å—Ç–µ–º —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π...")
    rec_systems = prepare_recommendation_systems(clicked_df, n_recommendations)
    
    print("=" * 80)
    print("–°–†–ê–í–ù–ï–ù–ò–ï –¢–†–ï–• –ú–ï–¢–û–î–û–í –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ô")
    print("=" * 80)
    print(f"1. –°–µ–≥–º–µ–Ω—Ç–Ω—ã–µ —Ç–æ–ø—ã (–ø–æ–ª √ó –≤–æ–∑—Ä–∞—Å—Ç)")
    print(f"2. –û–±—â–∏–π —Ç–æ–ø-{n_recommendations} –¥–ª—è –≤—Å–µ—Ö")
    print(f"3. –°–ª—É—á–∞–π–Ω—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏")
    print("=" * 80)
    
    # 1. –û–°–ù–û–í–ù–´–ï –ú–ï–¢–†–ò–ö–ò
    print("\nüìä –û–°–ù–û–í–ù–´–ï –ú–ï–¢–†–ò–ö–ò")
    print("-" * 60)
    metrics = evaluate_all_methods(clicked_df, rec_systems, n_recommendations)
    
    # –¢–∞–±–ª–∏—Ü–∞ —Å –º–µ—Ç—Ä–∏–∫–∞–º–∏
    methods = ['segment', 'global', 'random']
    method_names = ['–°–µ–≥–º–µ–Ω—Ç–Ω—ã–µ —Ç–æ–ø—ã', '–û–±—â–∏–π —Ç–æ–ø', '–†–∞–Ω–¥–æ–º']
    
    print(f"\n{'–ú–µ—Ç–æ–¥':<20} {'Hit Rate':<12} {'Avg Clicks':<12} {'Precision':<12} {'Users w/hits':<12}")
    print("-" * 68)
    
    for method, name in zip(methods, method_names):
        print(f"{name:<20} "
              f"{metrics[method]['hit_rate']:<12.4f} "
              f"{metrics[method]['avg_clicks_in_top']:<12.4f} "
              f"{metrics[method]['precision']:<12.4f} "
              f"{metrics[method]['users_with_hits']:<12.0f}")
    
    # –£–ª—É—á—à–µ–Ω–∏—è
    print("\nüìà –£–õ–£–ß–®–ï–ù–ò–Ø –û–¢–ù–û–°–ò–¢–ï–õ–¨–ù–û –ë–ê–ó–û–í–´–• –ú–ï–¢–û–î–û–í")
    print("-" * 60)
    print(f"\n–°–µ–≥–º–µ–Ω—Ç–Ω—ã–µ —Ç–æ–ø—ã vs –†–∞–Ω–¥–æ–º:")
    print(f"  Hit Rate: +{metrics['segment_vs_random']['hit_rate_improvement']:.1f}%")
    print(f"  Avg clicks: +{metrics['segment_vs_random']['avg_clicks_improvement']:.1f}%")
    print(f"  Precision: +{metrics['segment_vs_random']['precision_improvement']:.1f}%")
    
    print(f"\n–û–±—â–∏–π —Ç–æ–ø vs –†–∞–Ω–¥–æ–º:")
    print(f"  Hit Rate: +{metrics['global_vs_random']['hit_rate_improvement']:.1f}%")
    print(f"  Avg clicks: +{metrics['global_vs_random']['avg_clicks_improvement']:.1f}%")
    print(f"  Precision: +{metrics['global_vs_random']['precision_improvement']:.1f}%")
    
    print(f"\n–°–µ–≥–º–µ–Ω—Ç–Ω—ã–µ —Ç–æ–ø—ã vs –û–±—â–∏–π —Ç–æ–ø:")
    hit_rate_diff = metrics['segment_vs_global']['hit_rate_improvement']
    clicks_diff = metrics['segment_vs_global']['avg_clicks_improvement']
    precision_diff = metrics['segment_vs_global']['precision_improvement']
    
    print(f"  Hit Rate: {hit_rate_diff:+.1f}%")
    print(f"  Avg clicks: {clicks_diff:+.1f}%")
    print(f"  Precision: {precision_diff:+.1f}%")
    
    # 2. PRECISION@K
    print("\nüìè PRECISION@K –î–õ–Ø –†–ê–ó–ù–´–• K")
    print("-" * 60)
    precision_df = calculate_precision_at_k_all_methods(clicked_df, rec_systems)
    
    # –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –≤—ã–≤–æ–¥
    print(f"\n{'K':<5} {'Segment':<12} {'Global':<12} {'Random':<12} {'Seg vs Rand':<15} {'Seg vs Glob':<15}")
    print("-" * 71)
    for _, row in precision_df.iterrows():
        print(f"{row['K']:<5} "
              f"{row['Precision@K_segment']:<12.6f} "
              f"{row['Precision@K_global']:<12.6f} "
              f"{row['Precision@K_random']:<12.6f} "
              f"{row['Segment_vs_Random_%']:+<15.1f}% "
              f"{row['Segment_vs_Global_%']:+<15.1f}%")
    
    # 3. –ü–û–ö–†–´–¢–ò–ï –ö–ê–¢–ê–õ–û–ì–ê
    print("\nüìö –ü–û–ö–†–´–¢–ò–ï –ö–ê–¢–ê–õ–û–ì–ê –°–¢–ê–¢–ï–ô")
    print("-" * 60)
    coverage = analyze_coverage_all_methods(clicked_df, rec_systems, n_recommendations)
    
    print(f"–°–µ–≥–º–µ–Ω—Ç–Ω—ã–µ —Ç–æ–ø—ã:")
    print(f"  –ü–æ–∫—Ä—ã—Ç–∏–µ: {coverage['segment_coverage']:.4f} ({coverage['segment_unique_articles']} —Å—Ç–∞—Ç–µ–π)")
    print(f"  Gini –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç: {coverage['segment_gini']:.4f}")
    
    print(f"\n–û–±—â–∏–π —Ç–æ–ø:")
    print(f"  –ü–æ–∫—Ä—ã—Ç–∏–µ: {coverage['global_coverage']:.4f} ({coverage['global_unique_articles']} —Å—Ç–∞—Ç–µ–π)")
    
    print(f"\n–†–∞–Ω–¥–æ–º (—Å–∏–º—É–ª—è—Ü–∏—è):")
    print(f"  –ü–æ–∫—Ä—ã—Ç–∏–µ: {coverage['random_coverage']:.4f}")
    
    print(f"\n–ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç—ã –∫–æ–Ω—Ü–µ–Ω—Ç—Ä–∞—Ü–∏–∏ (–º–µ–Ω—å—à–µ = –±–æ–ª–µ–µ —Å–∫–æ–Ω—Ü–µ–Ω—Ç—Ä–∏—Ä–æ–≤–∞–Ω–æ):")
    print(f"  –°–µ–≥–º–µ–Ω—Ç—ã/–†–∞–Ω–¥–æ–º: {coverage['concentration_ratio_segment_vs_random']:.2f}x")
    print(f"  –û–±—â–∏–π —Ç–æ–ø/–†–∞–Ω–¥–æ–º: {coverage['concentration_ratio_global_vs_random']:.2f}x")
    
    # 4. –°–¢–ê–¢–ò–°–¢–ò–ß–ï–°–ö–ê–Ø –ó–ù–ê–ß–ò–ú–û–°–¢–¨
    print("\nüî¨ –°–¢–ê–¢–ò–°–¢–ò–ß–ï–°–ö–ê–Ø –ó–ù–ê–ß–ò–ú–û–°–¢–¨ (Bootstrap, n=1000)")
    print("-" * 60)
    
    significance = statistical_significance_test(clicked_df, rec_systems, n_recommendations)
    
    for comparison, label in [
        ('segment_vs_random', '–°–µ–≥–º–µ–Ω—Ç–Ω—ã–µ —Ç–æ–ø—ã vs –†–∞–Ω–¥–æ–º'),
        ('global_vs_random', '–û–±—â–∏–π —Ç–æ–ø vs –†–∞–Ω–¥–æ–º'),
        ('segment_vs_global', '–°–µ–≥–º–µ–Ω—Ç–Ω—ã–µ —Ç–æ–ø—ã vs –û–±—â–∏–π —Ç–æ–ø')
    ]:
        result = significance[comparison]
        print(f"\n{label}:")
        print(f"  –°—Ä–µ–¥–Ω—è—è —Ä–∞–∑–Ω–∏—Ü–∞: {result['mean_diff']:.4f}")
        print(f"  95% CI: [{result['ci_95'][0]:.4f}, {result['ci_95'][1]:.4f}]")
        print(f"  p-value: {result['p_value']:.4f}")
        
        if result['significant']:
            print(f"  ‚úÖ –°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏ –∑–Ω–∞—á–∏–º–æ (p < 0.05)")
        else:
            print(f"  ‚ùå –°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏ –ù–ï –∑–Ω–∞—á–∏–º–æ")
    
    # 5. –í–´–í–û–î–´
    print("\n" + "=" * 80)
    print("üí° –í–´–í–û–î–´")
    print("=" * 80)
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ª—É—á—à–∏–π –º–µ—Ç–æ–¥
    best_method = max(methods[:2], key=lambda m: metrics[m]['hit_rate'])
    best_name = method_names[methods.index(best_method)]
    
    print(f"\n1. –õ—É—á—à–∏–π –º–µ—Ç–æ–¥ –ø–æ Hit Rate: {best_name}")
    print(f"2. –£–ª—É—á—à–µ–Ω–∏–µ –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ —Ä–∞–Ω–¥–æ–º–∞: "
          f"{metrics[f'{best_method}_vs_random']['hit_rate_improvement']:.1f}%")
    
    if abs(metrics['segment_vs_global']['hit_rate_improvement']) < 5:
        print("3. –°–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è –∏ –æ–±—â–∏–π —Ç–æ–ø –ø–æ–∫–∞–∑—ã–≤–∞—é—Ç —Å–æ–ø–æ—Å—Ç–∞–≤–∏–º—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã (—Ä–∞–∑–Ω–∏—Ü–∞ < 5%)")
        print("   ‚Üí –ú–æ–∂–Ω–æ –Ω–∞—á–∞—Ç—å —Å –æ–±—â–µ–≥–æ —Ç–æ–ø–∞ (–ø—Ä–æ—â–µ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è)")
    elif metrics['segment_vs_global']['hit_rate_improvement'] > 0:
        print("3. –°–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è –¥–∞–µ—Ç –∑–∞–º–µ—Ç–Ω–æ–µ —É–ª—É—á—à–µ–Ω–∏–µ –Ω–∞–¥ –æ–±—â–∏–º —Ç–æ–ø–æ–º")
        print("   ‚Üí –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Å–µ–≥–º–µ–Ω—Ç–Ω—ã–µ —Ç–æ–ø—ã")
    else:
        print("3. –û–±—â–∏–π —Ç–æ–ø —Ä–∞–±–æ—Ç–∞–µ—Ç –ª—É—á—à–µ —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏")
        print("   ‚Üí –í–æ–∑–º–æ–∂–Ω–æ, –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–æ–π —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏")
    
    print("\n" + "=" * 80)
    
    return rec_systems, metrics


def save_recommendations(rec_systems: Dict, output_prefix: str = 'recommendations'):
    """
    –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤—Å–µ—Ö —Å–∏—Å—Ç–µ–º —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –≤ —Ñ–∞–π–ª—ã
    """
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å–µ–≥–º–µ–Ω—Ç–Ω—ã–µ —Ç–æ–ø—ã
    with open(f'{output_prefix}_segment.pkl', 'wb') as f:
        pickle.dump(rec_systems['segment_tops'], f)
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ–±—â–∏–π —Ç–æ–ø
    with open(f'{output_prefix}_global.pkl', 'wb') as f:
        pickle.dump(rec_systems['global_top'], f)
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Å—Ç–∞—Ç—å—è—Ö
    rec_systems['articles_info'].to_csv(f'{output_prefix}_articles_info.csv', index=False)
    
    print(f"‚úÖ –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã —Å –ø—Ä–µ—Ñ–∏–∫—Å–æ–º '{output_prefix}'")


# –§—É–Ω–∫—Ü–∏–∏ –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π
def recommend_by_segment(gender: int, age: int, rec_systems: Dict, n: int = 10) -> pd.DataFrame:
    """–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏"""
    group = age_group(age)
    segment_tops = rec_systems['segment_tops']
    articles_info = rec_systems['articles_info']
    
    ids = segment_tops.get((gender, group), [])[:n]
    recs = articles_info[articles_info['article_id'].isin(ids)]
    recs['article_id'] = pd.Categorical(recs['article_id'], categories=ids, ordered=True)
    recs = recs.sort_values('article_id')
    return recs[['article_id', 'title', 'url']].reset_index(drop=True)


def recommend_global(rec_systems: Dict, n: int = 10) -> pd.DataFrame:
    """–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –æ–±—â–µ–≥–æ —Ç–æ–ø–∞"""
    global_top = rec_systems['global_top'][:n]
    articles_info = rec_systems['articles_info']
    
    recs = articles_info[articles_info['article_id'].isin(global_top)]
    recs['article_id'] = pd.Categorical(recs['article_id'], categories=global_top, ordered=True)
    recs = recs.sort_values('article_id')
    return recs[['article_id', 'title', 'url']].reset_index(drop=True)


def recommend_random(rec_systems: Dict, n: int = 10) -> pd.DataFrame:
    """–°–ª—É—á–∞–π–Ω—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏"""
    all_articles = rec_systems['all_articles']
    articles_info = rec_systems['articles_info']
    
    random_ids = random.sample(all_articles, min(n, len(all_articles)))
    recs = articles_info[articles_info['article_id'].isin(random_ids)]
    return recs[['article_id', 'title', 'url']].reset_index(drop=True)


# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
if __name__ == "__main__":
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ
    data = pd.read_excel("../cuprum_3.xlsx", sheet_name="–õ–∏—Å—Ç4")
    data.drop(columns=["esb_ehr_id","patientnet_ehr_id"], inplace=True)
    data.rename(columns={"–ø–æ–ª":"gender", "–≤–æ–∑—Ä–∞—Å—Ç":"age"}, inplace=True)
    #data = data[data['tags'] != '–°–µ–∫—Å']
    data['age_group'] = data['age'].apply(age_group)
    clicked = data[data['action_type'] == 'CLICKED']
    
    # –°—Ç—Ä–æ–∏–º —Å–∏—Å—Ç–µ–º—É
    print_full_comparison_report(clicked)
    #rec_systems = prepare_recommendation_systems(clicked)
    #evaluate_all_methods(rec_systems)
    #print_full_comparison_report(rec_systems)
    
    
    # –ü—Ä–∏–º–µ—Ä: –ø–æ–∫–∞–∑–∞—Ç—å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
    #print("–°–µ–≥–º–µ–Ω—Ç–Ω—ã–µ:", recommend_segment(rec_systems, gender="–ú", age=35, n=5))
    #print("–ì–ª–æ–±–∞–ª—å–Ω—ã–µ:", recommend_global(rec_systems, n=5))
    #print("–†–∞–Ω–¥–æ–º–Ω—ã–µ:", recommend_random(rec_systems, n=5))
    # –ó–∞–ø—É—Å–∫–∞–µ–º